<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Saliency Weighted Convolutional Features for Instance Search</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Saliency Weighted Convolutional Features for Instance Search</h1>
      <a href="https://github.com/imatge-upc/salbow" class="btn">View on GitHub</a>
      <a href="https://github.com/imatge-upc/salbow/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/imatge-upc/salbow/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">

<table>
<thead>
<tr>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/retrieval-2016-lostobject/master/authors/Eva.jpg?token=AKsMd4iuttxHH44mYL3mPpJEtSvXVXF8ks5Xe-AWwA%3D%3D" alt="Eva Mohedano" title="Eva Mohedano"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/retrieval-2016-lostobject/master/authors/Kevin.jpg?token=AKsMd4VU31T7Bh8CztufWEWNudazbB_Uks5Xe-AxwA%3D%3D" alt="Kevin McGuinness" title="Kevin McGuinness"></th>
<th align="center"><img src="https://raw.githubusercontent.com/evamohe/BoW_CNN_InstanceSearch/master/authors/giro.jpg?token=AHPpwDdVdPYfMIwMBgHbjK9pPMJva1GOks5X1vHIwA%3D%3D" alt="Xavier Giro-i-Nieto" title="Xavier Giro-i-Nieto"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/retrieval-2016-lostobject/master/authors/Noel.jpg?token=AKsMdyemO5eJke9B9rqdRtA7otJscq1wks5Xe-BEwA%3D%3D" alt="Noel O'Connor" title="Noel O'Connor"></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://www.insight-centre.org/users/eva-mohedano">Eva Mohedano</a></td>
<td align="center"><a href="https://www.insight-centre.org/users/kevin-mcguinness">Kevin McGuinness</a></td>
<td align="center"><a href="https://imatge.upc.edu/web/people/xavier-giro">Xavier Giro-i-Nieto</a></td>
<td align="center"><a href="https://www.insight-centre.org/users/noel-oconnor">Noel O'Connor</a></td>
</tr>
</tbody>
</table>

<p>A joint collaboration between:</p>

<table>
<thead>
<tr>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/insight.jpg" alt="logo-insight" title="Insight Centre for Data Analytics"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/dcu.png" alt="logo-dcu" title="Dublin City University"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/upc.jpg" alt="logo-upc" title="Universitat Politecnica de Catalunya"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/etsetb.png" alt="logo-etsetb" title="ETSETB TelecomBCN"></th>
<th align="center"><img src="https://raw.githubusercontent.com/imatge-upc/saliency-2016-cvpr/master/logos/gpi.png" alt="logo-gpi" title="UPC Image Processing Group"></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><a href="https://www.insight-centre.org/">Insight Centre for Data Analytics</a></td>
<td align="center"><a href="http://www.dcu.ie/">Dublin City University (DCU)</a></td>
<td align="center"><a href="http://www.upc.edu/?set_language=en">Universitat Politecnica de Catalunya (UPC)</a></td>
<td align="center"><a href="https://www.etsetb.upc.edu/en/">UPC ETSETB TelecomBCN</a></td>
<td align="center"><a href="https://imatge.upc.edu/web/">UPC Image Processing Group</a></td>
</tr>
</tbody>
</table>

<h2>
<a id="abstract" class="anchor" href="#abstract" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Abstract</h2>

<p>This work explores attention models to weight the contribution of local convolutional representations for the instance search task. We present a retrieval framework based on bags of local convolutional features (BLCF) that benefits from saliency weighting to build an efficient image representation. The use of human visual attention models (saliency) allows significant improvements in retrieval performance without the need to conduct region analysis or spatial verification, and without requiring any feature fine tuning. We investigate the impact of different saliency models, finding that higher performance on saliency benchmarks does not necessarily equate to improved performance when used in instance search tasks. The proposed approach outperforms the state-of-the-art on the challenging INSTRE benchmark by a large margin, and provides similar performance on the Oxford and Paris benchmarks compared to more complex methods that use off-the-shelf representations.</p>
<table>
<thead>
<tr>
<th align="center"><img src="./figures/pipeline.png" width="100" alt="Scheme saliency weighting" title="Saliency weighting"></th>
</tr>
</thead>
</table>
      
      
      
<h2>
<a id="publication" class="anchor" href="#publication" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Publication</h2>

<p>Find our paper at <a href="linktoarXiv">arXiv</a>.</p>


<p>Please cite with the following Bibtex code:</p>

<pre><code> TO APPEAR
</code></pre>
     
<h2>
<a id="downloads" class="anchor" href="#downloads" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Downloads</h2>
<ul>
<p> <a href="https://drive.google.com/drive/folders/1BfG6n-8MFTCwSTl4dMR-8l8YQA3ge0Rg?usp=sharing"> Saliency predictions </a>.</p>
<p> <a href="https://drive.google.com/file/d/19bUlUVxxZgzpPV0p9SLx4DMJNkSW-Wtx/view?usp=sharing"> Pre-computed vocabularies, assignments and raw convolutional features. </a>.</p>
</ul>

<h2>
<a id="datasets" class="anchor" href="#datasets" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Datasets</h2>
Datasets are automatically downloaded from:
<ul>
  <p> <a href="https://drive.google.com/file/d/19bUlUVxxZgzpPV0p9SLx4DMJNkSW-Wtx/view?usp=sharing">INSTRE</a>, using the evaluation procol from <a href="https://drive.google.com/file/d/19bUlUVxxZgzpPV0p9SLx4DMJNkSW-Wtx/view?usp=sharing"> Iscen et al.</a></p>
  <p> <a href="http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/">Oxford Buildings</a> and <a href="http://www.robots.ox.ac.uk/~vgg/data/parisbuildings/">Paris Buildings</a> datasets, using the standard evaluation protocol.</p>
</ul>

  </body>
</html>
